import os
import json
import torch
import numpy as np
import pandas as pd
import shap
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


# ================== ä¸“ä¸šç´«è‰²é…è‰²æ–¹æ¡ˆ ==================
class PurpleColorPalette:
    """ç´«è‰²ç³»é…è‰²æ–¹æ¡ˆ"""

    @staticmethod
    def get_purple_cmap():
        """è·å–ç´«è‰²æ¸å˜è‰²å½©æ˜ å°„"""
        colors = [
            '#F3E5F5',  # æµ…ç´«
            '#E1BEE7',  # æ·¡ç´«
            '#CE93D8',  # ç´«ä¸é¦™
            '#BA68C8',  # ä¸­ç´«
            '#AB47BC',  # ç´«æ°´æ™¶
            '#9C27B0',  # ç´«è‰²
            '#8E24AA',  # ç´«ç½—å…°
            '#7B1FA2',  # æ·±ç´«
            '#6A1B9A',  # è“ç´«
            '#4A148C',  # æ·±è“ç´«
        ]
        return sns.color_palette(colors, as_cmap=True)

    @staticmethod
    def get_shap_cmap():
        """è·å–SHAPé£æ ¼çš„çº¢-è“-ç´«æ¸å˜"""
        from matplotlib.colors import LinearSegmentedColormap
        return LinearSegmentedColormap.from_list(
            'shap_purple',
            ['#FF0000', '#FF6B6B', '#FFA8A8', '#FFFFFF', '#E6E6FA', '#9370DB', '#4B0082']
        )

    @staticmethod
    def get_sequential_purple():
        """é¡ºåºç´«è‰²è°ƒè‰²æ¿"""
        return sns.color_palette("magma", as_cmap=True)

    @staticmethod
    def get_bar_colors(values, cmap_name='purple'):
        """æ ¹æ®å€¼è·å–æ¡å½¢å›¾é¢œè‰²"""
        if cmap_name == 'purple':
            norm_vals = (values - values.min()) / (values.max() - values.min() + 1e-8)
            cmap = plt.cm.Purples
            return [cmap(v) for v in norm_vals]
        elif cmap_name == 'red_blue':
            colors = []
            for v in values:
                if v >= 0:
                    intensity = min(abs(v) / (abs(values).max() + 1e-8), 0.8)
                    colors.append((1.0, 0.7 - 0.6 * intensity, 0.7 - 0.6 * intensity))
                else:
                    intensity = min(abs(v) / (abs(values).max() + 1e-8), 0.8)
                    colors.append((0.7 - 0.6 * intensity, 0.7 - 0.6 * intensity, 1.0))
            return colors
        elif cmap_name == 'magma':
            cmap = plt.cm.magma
            norm_vals = (values - values.min()) / (values.max() - values.min() + 1e-8)
            return [cmap(v) for v in norm_vals]


# ================== ä¿®å¤çš„SHAPåˆ†æå™¨ ==================
class FixedSHAPAnalyzer:
    """ä¿®å¤çš„SHAPåˆ†æå™¨"""

    def __init__(self, model_path):
        self.model_path = model_path
        print(f"ğŸ“¥ åŠ è½½æ¨¡å‹: {model_path}")
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {self.device}")
        self.model.to(self.device)
        self.model.eval()

    def predict_proba(self, texts):
        """é¢„æµ‹å‡½æ•° - ç”¨äºSHAPè§£é‡Šå™¨"""
        if isinstance(texts, str):
            texts = [texts]

        # ç¼–ç æ–‡æœ¬
        encodings = self.tokenizer(
            texts,
            truncation=True,
            padding=True,
            max_length=512,
            return_tensors='pt'
        ).to(self.device)

        # é¢„æµ‹
        with torch.no_grad():
            outputs = self.model(**encodings)
            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)

        return probs.cpu().numpy()

    def create_sample_texts(self):
        """åˆ›å»ºç¤ºä¾‹æ–‡æœ¬"""
        samples = [
            "è¢«å‘Šäººç›—çªƒä»–äººæ‰‹æœºä»·å€¼5000å…ƒ [SEP] ç›—çªƒç½ªæ˜¯æŒ‡ä»¥éæ³•å æœ‰ä¸ºç›®çš„ï¼Œç§˜å¯†çªƒå–å…¬ç§è´¢ç‰©æ•°é¢è¾ƒå¤§çš„è¡Œä¸ºã€‚",
            "äº¤é€šäº‹æ•…è‡´ä¸€äººæ­»äº¡ä¸¤äººå—ä¼¤ [SEP] äº¤é€šè‚‡äº‹ç½ªæ˜¯æŒ‡è¿åäº¤é€šè¿è¾“ç®¡ç†æ³•è§„ï¼Œå› è€Œå‘ç”Ÿé‡å¤§äº‹æ•…çš„è¡Œä¸ºã€‚",
            "åˆåŒçº çº·æ¶‰åŠè¿çº¦é‡‘æ”¯ä»˜100ä¸‡å…ƒ [SEP] åˆåŒçº çº·çš„è§£å†³éœ€ä¾æ®åˆåŒçº¦å®šå’Œç›¸å…³æ³•å¾‹è§„å®šï¼Œç‰¹åˆ«æ˜¯å…³äºè¿çº¦é‡‘çš„éƒ¨åˆ†ã€‚",
            "æ•…æ„ä¼¤å®³è‡´äººè½»ä¼¤äºŒçº§ [SEP] æ•…æ„ä¼¤å®³ç½ªæ ¹æ®ä¼¤å®³ç¨‹åº¦åˆ†ä¸ºè½»ä¼¤ã€é‡ä¼¤å’Œè‡´äººæ­»äº¡ï¼Œè½»ä¼¤äºŒçº§å±äºè½»ä¼¤èŒƒç•´ã€‚",
            "è´ªæ±¡å…¬æ¬¾150ä¸‡å…ƒ [SEP] è´ªæ±¡ç½ªæ˜¯æŒ‡å›½å®¶å·¥ä½œäººå‘˜åˆ©ç”¨èŒåŠ¡ä¸Šçš„ä¾¿åˆ©ï¼Œä¾µåã€çªƒå–ã€éª—å–å…¬å…±è´¢ç‰©çš„è¡Œä¸ºã€‚"
        ]
        return samples

    def analyze_with_fixed_beeswarm(self, output_path='./shap_fixed/beeswarm.png'):
        """ä½¿ç”¨ä¿®å¤çš„æ–¹æ³•ç”Ÿæˆèœ‚ç¾¤å›¾"""
        print("ğŸ ç”Ÿæˆèœ‚ç¾¤å›¾...")

        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        # è·å–æ ·æœ¬æ–‡æœ¬
        texts = self.create_sample_texts()

        try:
            # æ–¹æ³•1ï¼šä½¿ç”¨æ­£ç¡®çš„Explaineræ ¼å¼
            explainer = shap.Explainer(
                self.predict_proba,
                self.tokenizer,
                algorithm='permutation'
            )

            # è®¡ç®—SHAPå€¼
            shap_values = explainer(texts)

            # ç»˜åˆ¶èœ‚ç¾¤å›¾
            plt.figure(figsize=(14, 8))
            shap.plots.beeswarm(shap_values, show=False, max_display=15)

            # ç¾åŒ–
            ax = plt.gca()
            ax.set_facecolor('#FAF9F6')
            ax.figure.set_facecolor('#FAF9F6')
            ax.set_title('SHAPèœ‚ç¾¤å›¾ - æ³•å¾‹ç‰¹å¾é‡è¦æ€§', fontsize=16,
                         fontweight='bold', color='#6A5ACD')

            plt.tight_layout()
            plt.savefig(output_path, dpi=300, bbox_inches='tight',
                        facecolor='#FAF9F6', edgecolor='none')
            plt.close()

            print(f"âœ… èœ‚ç¾¤å›¾å·²ä¿å­˜: {output_path}")
            return shap_values

        except Exception as e:
            print(f"âš ï¸ èœ‚ç¾¤å›¾ç”Ÿæˆå¤±è´¥: {e}")
            print("å°è¯•å¤‡ç”¨æ–¹æ³•...")
            return self._alternative_beeswarm(texts, output_path)

    def _alternative_beeswarm(self, texts, output_path):
        """å¤‡ç”¨æ–¹æ³•ï¼šæ‰‹åŠ¨è®¡ç®—ç‰¹å¾é‡è¦æ€§"""
        print("ä½¿ç”¨å¤‡ç”¨æ–¹æ³•è®¡ç®—ç‰¹å¾é‡è¦æ€§...")

        # è®¡ç®—æ¯ä¸ªtokençš„é‡è¦æ€§
        token_importance = {}

        for text in texts:
            # è·å–åŸå§‹é¢„æµ‹
            original_probs = self.predict_proba(text)[0]

            # åˆ†è¯
            words = text.split()

            for i, word in enumerate(words):
                if word not in ['[SEP]', '[CLS]']:
                    # é®ç›–å½“å‰è¯
                    masked_words = words.copy()
                    masked_words[i] = '[MASK]'
                    masked_text = ' '.join(masked_words)

                    # é¢„æµ‹é®ç›–åçš„æ–‡æœ¬
                    masked_probs = self.predict_proba(masked_text)[0]

                    # è®¡ç®—é‡è¦æ€§ï¼ˆæ¦‚ç‡å˜åŒ–ï¼‰
                    importance = np.abs(original_probs - masked_probs).sum()

                    # ç´¯åŠ 
                    if word in token_importance:
                        token_importance[word] += importance
                    else:
                        token_importance[word] = importance

        # æ’åºå¹¶é€‰æ‹©å‰20ä¸ª
        top_tokens = sorted(token_importance.items(), key=lambda x: x[1], reverse=True)[:20]

        # åˆ›å»ºæ¡å½¢å›¾
        words = [t[0] for t in top_tokens]
        importances = [t[1] for t in top_tokens]

        # ä½¿ç”¨ç´«è‰²æ¸å˜
        colors = PurpleColorPalette.get_bar_colors(np.array(importances), 'purple')

        # ç»˜åˆ¶å›¾è¡¨
        fig, ax = plt.subplots(figsize=(14, 8))
        bars = ax.barh(range(len(words)), importances, color=colors, edgecolor='#4B0082')

        # ç¾åŒ–
        ax.set_yticks(range(len(words)))
        ax.set_yticklabels(words, fontsize=11)
        ax.set_xlabel('ç‰¹å¾é‡è¦æ€§', fontsize=12)
        ax.set_title('Top 20 é‡è¦æ³•å¾‹ç‰¹å¾ï¼ˆé®ç›–æ³•ï¼‰', fontsize=16,
                     fontweight='bold', color='#6A5ACD')
        ax.grid(True, axis='x', alpha=0.3, linestyle='--')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, importances):
            width = bar.get_width()
            ax.text(width + max(importances) * 0.01, bar.get_y() + bar.get_height() / 2,
                    f'{value:.4f}', ha='left', va='center', fontsize=10)

        ax.set_facecolor('#FAF9F6')
        fig.patch.set_facecolor('#FAF9F6')

        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜: {output_path}")
        return top_tokens

    def analyze_with_waterfall(self, output_dir='./shap_fixed/waterfall'):
        """ç”Ÿæˆç€‘å¸ƒå›¾"""
        print("ğŸŒŠ ç”Ÿæˆç€‘å¸ƒå›¾...")

        os.makedirs(output_dir, exist_ok=True)

        texts = self.create_sample_texts()

        for i, text in enumerate(texts[:3]):  # åªåˆ†æå‰3ä¸ªæ ·æœ¬
            try:
                # ä½¿ç”¨Permutationè§£é‡Šå™¨
                explainer = shap.Explainer(
                    self.predict_proba,
                    masker=self.tokenizer,
                    algorithm='permutation'
                )

                # è®¡ç®—SHAPå€¼
                shap_values = explainer([text])

                # ç»˜åˆ¶ç€‘å¸ƒå›¾
                plt.figure(figsize=(12, 6))
                shap.plots.waterfall(shap_values[0], max_display=10, show=False)

                # ç¾åŒ–
                ax = plt.gca()
                ax.set_title(f'ç€‘å¸ƒå›¾ - æ ·æœ¬ {i + 1}', fontsize=14,
                             fontweight='bold', color='#6A5ACD')
                ax.set_facecolor('#FAF9F6')
                ax.figure.set_facecolor('#FAF9F6')

                # ä¿å­˜
                output_path = os.path.join(output_dir, f'waterfall_{i + 1}.png')
                plt.tight_layout()
                plt.savefig(output_path, dpi=300, bbox_inches='tight',
                            facecolor='#FAF9F6', edgecolor='none')
                plt.close()

                print(f"  âœ… ç€‘å¸ƒå›¾ {i + 1}: {output_path}")

            except Exception as e:
                print(f"  âš ï¸ ç€‘å¸ƒå›¾ {i + 1} ç”Ÿæˆå¤±è´¥: {e}")
                # å°è¯•ç”Ÿæˆç®€å•çš„æ¡å½¢å›¾æ›¿ä»£
                self._create_simple_waterfall(text, i, output_dir)

    def _create_simple_waterfall(self, text, idx, output_dir):
        """åˆ›å»ºç®€å•çš„ç€‘å¸ƒå›¾æ›¿ä»£"""
        # åˆ†è¯
        words = text.split()[:15]  # åªå–å‰15ä¸ªè¯

        # è®¡ç®—æ¯ä¸ªè¯çš„é‡è¦æ€§
        original_probs = self.predict_proba(text)[0]
        importances = []

        for i, word in enumerate(words):
            if word not in ['[SEP]', '[CLS]']:
                # é®ç›–
                masked_words = text.split()
                masked_words[i] = '[MASK]'
                masked_text = ' '.join(masked_words)
                masked_probs = self.predict_proba(masked_text)[0]

                # é‡è¦æ€§
                importance = (original_probs - masked_probs).sum()
                importances.append(importance)
            else:
                importances.append(0)

        # ç»˜åˆ¶
        fig, ax = plt.subplots(figsize=(12, 6))

        # è®¡ç®—ç´¯è®¡å€¼
        cumulative = 0
        for i, (word, imp) in enumerate(zip(words, importances)):
            if i == 0:
                ax.bar(i, imp, color='#E6E6FA', edgecolor='#4B0082')
            else:
                ax.bar(i, imp, bottom=cumulative, color='#9370DB' if imp > 0 else '#FF6B6B',
                       edgecolor='#4B0082')
            cumulative += imp

        # æ·»åŠ è¿æ¥çº¿
        for i in range(len(words) - 1):
            x1, x2 = i, i + 1
            y1 = sum(importances[:i + 1])
            y2 = sum(importances[:i + 2])
            ax.plot([x1, x2], [y1, y2], 'k-', alpha=0.3)

        # ç¾åŒ–
        ax.set_xticks(range(len(words)))
        ax.set_xticklabels(words, rotation=45, ha='right', fontsize=10)
        ax.set_ylabel('ç´¯è®¡SHAPå€¼', fontsize=12)
        ax.set_title(f'ç€‘å¸ƒå›¾ - æ ·æœ¬ {idx + 1} (ç®€åŒ–ç‰ˆ)', fontsize=14,
                     fontweight='bold', color='#6A5ACD')
        ax.grid(True, alpha=0.3)
        ax.axhline(y=0, color='k', linestyle='-', alpha=0.3)

        ax.set_facecolor('#FAF9F6')
        fig.patch.set_facecolor('#FAF9F6')

        output_path = os.path.join(output_dir, f'waterfall_{idx + 1}_simple.png')
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"  âœ… ç®€åŒ–ç€‘å¸ƒå›¾ {idx + 1}: {output_path}")

    def create_heatmap_analysis(self, output_path='./shap_fixed/heatmap.png'):
        """åˆ›å»ºçƒ­åŠ›å›¾åˆ†æ"""
        print("ğŸ”¥ åˆ›å»ºçƒ­åŠ›å›¾...")

        texts = self.create_sample_texts()

        # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹æ¦‚ç‡
        all_probs = []
        for text in texts:
            probs = self.predict_proba(text)[0]
            all_probs.append(probs)

        all_probs = np.array(all_probs)

        # åˆ›å»ºçƒ­åŠ›å›¾
        fig, ax = plt.subplots(figsize=(12, 8))

        # ä½¿ç”¨çº¢-è“-ç´«æ¸å˜
        cmap = PurpleColorPalette.get_shap_cmap()

        im = ax.imshow(all_probs, aspect='auto', cmap=cmap)

        # è®¾ç½®æ ‡ç­¾
        ax.set_xticks(range(4))
        ax.set_xticklabels(['ç›¸ä¼¼åº¦0', 'ç›¸ä¼¼åº¦1', 'ç›¸ä¼¼åº¦2', 'ç›¸ä¼¼åº¦3'], fontsize=12)
        ax.set_yticks(range(len(texts)))
        ax.set_yticklabels([f'æ¡ˆä¾‹{i + 1}' for i in range(len(texts))], fontsize=11)

        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(im, ax=ax)
        cbar.set_label('é¢„æµ‹æ¦‚ç‡', fontsize=12)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i in range(len(texts)):
            for j in range(4):
                ax.text(j, i, f'{all_probs[i, j]:.2f}',
                        ha='center', va='center', fontsize=10,
                        color='white' if all_probs[i, j] > 0.5 else 'black')

        ax.set_title('é¢„æµ‹æ¦‚ç‡çƒ­åŠ›å›¾', fontsize=16,
                     fontweight='bold', color='#6A5ACD', pad=20)
        ax.set_facecolor('#FAF9F6')
        fig.patch.set_facecolor('#FAF9F6')

        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… çƒ­åŠ›å›¾å·²ä¿å­˜: {output_path}")

    def create_radar_chart(self, output_path='./shap_fixed/radar.png'):
        """åˆ›å»ºé›·è¾¾å›¾"""
        print("ğŸ“¡ åˆ›å»ºé›·è¾¾å›¾...")

        texts = self.create_sample_texts()

        # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹æ¦‚ç‡
        all_probs = []
        categories = ['ç›—çªƒæ¡ˆ', 'äº¤é€šè‚‡äº‹', 'åˆåŒçº çº·', 'æ•…æ„ä¼¤å®³', 'è´ªæ±¡æ¡ˆ']

        for text in texts:
            probs = self.predict_proba(text)[0]
            all_probs.append(probs)

        all_probs = np.array(all_probs)

        # åˆ›å»ºé›·è¾¾å›¾
        fig = plt.figure(figsize=(10, 8))
        ax = fig.add_subplot(111, polar=True)

        # è§’åº¦
        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
        angles += angles[:1]  # é—­åˆ

        # ç»˜åˆ¶æ¯ä¸ªç›¸ä¼¼åº¦ç­‰çº§
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']

        for level in range(4):
            values = all_probs[:, level].tolist()
            values += values[:1]  # é—­åˆ

            ax.plot(angles, values, 'o-', linewidth=2,
                    label=f'ç›¸ä¼¼åº¦{level}', color=colors[level])
            ax.fill(angles, values, alpha=0.1, color=colors[level])

        # è®¾ç½®æ ‡ç­¾
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories, fontsize=12)

        # ç¾åŒ–
        ax.set_ylim(0, 1)
        ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])
        ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=10, color='gray')

        ax.grid(True, alpha=0.3)
        ax.set_facecolor('#FAF9F6')
        fig.patch.set_facecolor('#FAF9F6')

        plt.title('æ³•å¾‹æ¡ˆä¾‹ç›¸ä¼¼åº¦é¢„æµ‹é›·è¾¾å›¾', fontsize=16,
                  fontweight='bold', color='#6A5ACD', pad=20)
        plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))

        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… é›·è¾¾å›¾å·²ä¿å­˜: {output_path}")

    def run_full_analysis(self, output_dir='./shap_fixed_results'):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("=" * 60)
        print("ğŸ¨ ç¾è§‚çš„SHAPå¯è§£é‡Šæ€§åˆ†æ - ä¿®å¤ç‰ˆ")
        print("=" * 60)

        os.makedirs(output_dir, exist_ok=True)

        # 1. èœ‚ç¾¤å›¾
        print("\n1. ç”Ÿæˆèœ‚ç¾¤å›¾...")
        self.analyze_with_fixed_beeswarm(os.path.join(output_dir, 'beeswarm.png'))

        # 2. ç€‘å¸ƒå›¾
        print("\n2. ç”Ÿæˆç€‘å¸ƒå›¾...")
        self.analyze_with_waterfall(os.path.join(output_dir, 'waterfall'))

        # 3. çƒ­åŠ›å›¾
        print("\n3. ç”Ÿæˆçƒ­åŠ›å›¾...")
        self.create_heatmap_analysis(os.path.join(output_dir, 'heatmap.png'))

        # 4. é›·è¾¾å›¾
        print("\n4. ç”Ÿæˆé›·è¾¾å›¾...")
        self.create_radar_chart(os.path.join(output_dir, 'radar.png'))

        # 5. åˆ›å»ºHTMLæŠ¥å‘Š
        self.create_html_report(output_dir)

        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_dir}")

    def create_html_report(self, output_dir):
        """åˆ›å»ºHTMLæŠ¥å‘Š"""
        html_content = """
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>æ³•å¾‹æ¨¡å‹SHAPåˆ†ææŠ¥å‘Š - ä¿®å¤ç‰ˆ</title>
    <style>
        body {
            font-family: 'Microsoft YaHei', sans-serif;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        }
        .header {
            text-align: center;
            margin-bottom: 40px;
            padding-bottom: 20px;
            border-bottom: 3px solid #9370DB;
        }
        .header h1 {
            color: #4B0082;
            font-size: 2.2em;
            margin-bottom: 10px;
        }
        .chart-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));
            gap: 25px;
            margin-bottom: 40px;
        }
        .chart-card {
            background: #FAF9F6;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        }
        .chart-card h3 {
            color: #4B0082;
            margin-top: 0;
            border-left: 4px solid #9370DB;
            padding-left: 10px;
        }
        .chart-image {
            width: 100%;
            border-radius: 8px;
            border: 1px solid #E6E6FA;
        }
        .footer {
            text-align: center;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #E6E6FA;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“Š æ³•å¾‹åŒ¹é…æ¨¡å‹SHAPåˆ†ææŠ¥å‘Š</h1>
            <p>æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æ - ç´«è‰²æ¸å˜é…è‰²æ–¹æ¡ˆ</p>
        </div>

        <div class="chart-grid">
            <div class="chart-card">
                <h3>ğŸ èœ‚ç¾¤å›¾ - ç‰¹å¾åˆ†å¸ƒ</h3>
                <img src="beeswarm.png" alt="èœ‚ç¾¤å›¾" class="chart-image">
                <p>å±•ç¤ºç‰¹å¾é‡è¦æ€§åˆ†å¸ƒï¼Œé¢œè‰²è¡¨ç¤ºç‰¹å¾å€¼</p>
            </div>

            <div class="chart-card">
                <h3>ğŸ”¥ çƒ­åŠ›å›¾ - é¢„æµ‹æ¦‚ç‡</h3>
                <img src="heatmap.png" alt="çƒ­åŠ›å›¾" class="chart-image">
                <p>ä¸åŒæ¡ˆä¾‹çš„ç›¸ä¼¼åº¦é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ</p>
            </div>

            <div class="chart-card">
                <h3>ğŸ“¡ é›·è¾¾å›¾ - å¤šç»´åˆ†æ</h3>
                <img src="radar.png" alt="é›·è¾¾å›¾" class="chart-image">
                <p>å„æ¡ˆä¾‹åœ¨ä¸åŒç›¸ä¼¼åº¦ç­‰çº§çš„é¢„æµ‹åˆ†å¸ƒ</p>
            </div>

            <div class="chart-card">
                <h3>ğŸŒŠ ç€‘å¸ƒå›¾åˆ†æ</h3>
                <p>å•ä¸ªæ ·æœ¬çš„ç‰¹å¾è´¡çŒ®åˆ†è§£ï¼š</p>
                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 10px; margin-top: 10px;">
                    <img src="waterfall/waterfall_1.png" alt="ç€‘å¸ƒå›¾1" style="width: 100%; border-radius: 5px;">
                    <img src="waterfall/waterfall_2.png" alt="ç€‘å¸ƒå›¾2" style="width: 100%; border-radius: 5px;">
                </div>
            </div>
        </div>

        <div class="footer">
            <p>ğŸ“… æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š""" + pd.Timestamp.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S') + """</p>
            <p>ğŸ¨ é…è‰²æ–¹æ¡ˆï¼šçº¢-è“-ç´«æ¸å˜ | SHAPå¯è§£é‡Šæ€§åˆ†æ</p>
        </div>
    </div>
</body>
</html>
        """

        # ä¿å­˜HTMLæ–‡ä»¶
        html_path = os.path.join(output_dir, 'shap_report.html')
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)

        print(f"ğŸ“„ HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {html_path}")


# ================== ä¸»ç¨‹åº ==================
def main():
    # è®¾ç½®æ¨¡å‹è·¯å¾„
    MODEL_PATH = "E:\\Py_Dev\\IceBerg\\lawformer_matching_model"

    # æ£€æŸ¥æ¨¡å‹è·¯å¾„
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {MODEL_PATH}")
        return

    try:
        # åˆ›å»ºåˆ†æå™¨
        analyzer = FixedSHAPAnalyzer(MODEL_PATH)

        # è¿è¡Œå®Œæ•´åˆ†æ
        analyzer.run_full_analysis('./shap_fixed_results')

    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()