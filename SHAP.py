import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆå¦‚æœåˆ†æä¸­æ–‡æ–‡æœ¬ï¼‰
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class SimplePurpleAnalyzer:
    """ç®€åŒ–ä½†ç¾è§‚çš„ç´«è‰²é…è‰²åˆ†æå™¨"""

    def __init__(self, model_path):
        self.model_path = model_path
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        self.model.eval()

    def get_purple_colors(self, n_colors=10):
        """è·å–ç´«è‰²æ¸å˜é¢œè‰²"""
        base_colors = sns.color_palette("husl", n_colors)
        # è½¬æ¢ä¸ºç´«è‰²ç³»
        purple_colors = []
        for color in base_colors:
            # å¢å¼ºç´«è‰²æˆåˆ†
            r, g, b = color
            purple_colors.append((min(1.0, r * 0.5 + 0.5), min(1.0, g * 0.3 + 0.3), min(1.0, b * 0.7 + 0.3)))
        return purple_colors

    def analyze_token_importance(self, text, output_path='./token_importance.png'):
        """åˆ†ætokené‡è¦æ€§"""
        print("ğŸ” åˆ†ætokené‡è¦æ€§...")

        # åˆ†è¯
        tokens = self.tokenizer.tokenize(text)
        token_ids = self.tokenizer.encode(text, add_special_tokens=False)

        # è·å–åŸå§‹é¢„æµ‹
        inputs = self.tokenizer(text, return_tensors='pt').to(self.device)
        with torch.no_grad():
            outputs = self.model(**inputs)
            original_probs = torch.nn.functional.softmax(outputs.logits, dim=-1)[0]

        # è®¡ç®—æ¯ä¸ªtokençš„é‡è¦æ€§
        importances = []
        for i, (token, token_id) in enumerate(zip(tokens, token_ids)):
            # åˆ›å»ºé®ç›–æ–‡æœ¬
            masked_ids = token_ids.copy()
            masked_ids[i] = self.tokenizer.mask_token_id
            masked_text = self.tokenizer.decode(masked_ids)

            # é¢„æµ‹é®ç›–åæ–‡æœ¬
            masked_inputs = self.tokenizer(masked_text, return_tensors='pt').to(self.device)
            with torch.no_grad():
                masked_outputs = self.model(**masked_inputs)
                masked_probs = torch.nn.functional.softmax(masked_outputs.logits, dim=-1)[0]

            # è®¡ç®—é‡è¦æ€§ï¼ˆæ¦‚ç‡å·®å¼‚ï¼‰
            importance = torch.abs(original_probs - masked_probs).sum().item()
            importances.append((token, importance))

        # æ’åºå¹¶é€‰æ‹©å‰15ä¸ª
        importances.sort(key=lambda x: x[1], reverse=True)
        top_tokens = importances[:15]

        # åˆ›å»ºç¾è§‚çš„æ¡å½¢å›¾
        fig, ax = plt.subplots(figsize=(12, 8))

        tokens_list = [t[0] for t in top_tokens]
        values = [t[1] for t in top_tokens]

        # ä½¿ç”¨ç´«è‰²æ¸å˜
        colors = self.get_purple_colors(len(tokens_list))

        bars = ax.barh(range(len(tokens_list)), values, color=colors, edgecolor='#4B0082', linewidth=0.5)

        # ç¾åŒ–å›¾è¡¨
        ax.set_yticks(range(len(tokens_list)))
        ax.set_yticklabels(tokens_list, fontsize=11)
        ax.set_xlabel('é‡è¦æ€§åˆ†æ•°', fontsize=12, fontweight='bold')
        ax.set_title('Tokené‡è¦æ€§åˆ†æ - ç´«è‰²æ¸å˜', fontsize=16, fontweight='bold', color='#4B0082', pad=20)

        # æ·»åŠ ç½‘æ ¼
        ax.grid(True, axis='x', alpha=0.3, linestyle='--', color='gray')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, values):
            width = bar.get_width()
            ax.text(width + max(values) * 0.01, bar.get_y() + bar.get_height() / 2,
                    f'{value:.4f}', ha='left', va='center', fontsize=10,
                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))

        # è®¾ç½®èƒŒæ™¯è‰²
        ax.set_facecolor('#FAF9F6')
        fig.patch.set_facecolor('#FAF9F6')

        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… Tokené‡è¦æ€§å›¾å·²ä¿å­˜: {output_path}")

        return top_tokens

    def create_prediction_heatmap(self, texts, output_path='./prediction_heatmap.png'):
        """åˆ›å»ºé¢„æµ‹çƒ­åŠ›å›¾"""
        print("ğŸ”¥ åˆ›å»ºé¢„æµ‹çƒ­åŠ›å›¾...")

        # è®¡ç®—é¢„æµ‹æ¦‚ç‡
        all_probs = []
        for text in texts:
            inputs = self.tokenizer(text, return_tensors='pt').to(self.device)
            with torch.no_grad():
                outputs = self.model(**inputs)
                probs = torch.nn.functional.softmax(outputs.logits, dim=-1)[0]
                all_probs.append(probs.cpu().numpy())

        all_probs = np.array(all_probs)

        # åˆ›å»ºçƒ­åŠ›å›¾
        fig, ax = plt.subplots(figsize=(14, 8))

        # ä½¿ç”¨ç´«è‰²æ¸å˜è‰²å½©æ˜ å°„
        cmap = sns.color_palette("magma", as_cmap=True)

        im = ax.imshow(all_probs, aspect='auto', cmap=cmap)

        # è®¾ç½®æ ‡ç­¾
        ax.set_xticks(range(4))
        ax.set_xticklabels(['ç›¸ä¼¼åº¦ 0', 'ç›¸ä¼¼åº¦ 1', 'ç›¸ä¼¼åº¦ 2', 'ç›¸ä¼¼åº¦ 3'],
                           fontsize=12, fontweight='bold')
        ax.set_yticks(range(len(texts)))
        ax.set_yticklabels([f'æ¡ˆä¾‹ {i + 1}' for i in range(len(texts))],
                           fontsize=11, fontweight='bold')

        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(im, ax=ax, pad=0.02)
        cbar.set_label('é¢„æµ‹æ¦‚ç‡', fontsize=12, fontweight='bold')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i in range(len(texts)):
            for j in range(4):
                text_color = 'white' if all_probs[i, j] > 0.5 else 'black'
                ax.text(j, i, f'{all_probs[i, j]:.3f}',
                        ha='center', va='center', fontsize=10,
                        color=text_color, fontweight='bold')

        # ç¾åŒ–
        ax.set_title('æ³•å¾‹æ¡ˆä¾‹ç›¸ä¼¼åº¦é¢„æµ‹çƒ­åŠ›å›¾', fontsize=18,
                     fontweight='bold', color='#4B0082', pad=20)
        ax.set_facecolor('#F5F0FF')
        fig.patch.set_facecolor('#F5F0FF')

        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… é¢„æµ‹çƒ­åŠ›å›¾å·²ä¿å­˜: {output_path}")

        return all_probs

    def create_comparison_radar(self, texts, output_path='./comparison_radar.png'):
        """åˆ›å»ºæ¯”è¾ƒé›·è¾¾å›¾"""
        print("ğŸ“¡ åˆ›å»ºæ¯”è¾ƒé›·è¾¾å›¾...")

        # è®¡ç®—é¢„æµ‹æ¦‚ç‡
        all_probs = []
        for text in texts:
            inputs = self.tokenizer(text, return_tensors='pt').to(self.device)
            with torch.no_grad():
                outputs = self.model(**inputs)
                probs = torch.nn.functional.softmax(outputs.logits, dim=-1)[0]
                all_probs.append(probs.cpu().numpy())

        all_probs = np.array(all_probs)

        # åˆ›å»ºé›·è¾¾å›¾
        fig = plt.figure(figsize=(12, 10))
        ax = fig.add_subplot(111, polar=True)

        # è§’åº¦
        angles = np.linspace(0, 2 * np.pi, len(texts), endpoint=False).tolist()
        angles += angles[:1]  # é—­åˆ

        # ä½¿ç”¨ç´«è‰²ç³»é¢œè‰²
        colors = ['#9370DB', '#BA68C8', '#AB47BC', '#9C27B0', '#8E24AA']

        # ç»˜åˆ¶æ¯ä¸ªç›¸ä¼¼åº¦ç­‰çº§
        for level in range(4):
            values = all_probs[:, level].tolist()
            values += values[:1]  # é—­åˆ

            ax.plot(angles, values, 'o-', linewidth=3,
                    label=f'ç›¸ä¼¼åº¦ç­‰çº§ {level}', color=colors[level % len(colors)])
            ax.fill(angles, values, alpha=0.15, color=colors[level % len(colors)])

        # è®¾ç½®æ ‡ç­¾
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels([f'æ¡ˆä¾‹ {i + 1}' for i in range(len(texts))],
                           fontsize=12, fontweight='bold')

        # è®¾ç½®å¾„å‘æ ‡ç­¾
        ax.set_ylim(0, 1)
        ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])
        ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'],
                           fontsize=10, color='#666666')

        # ç¾åŒ–
        ax.grid(True, alpha=0.3, linestyle='--')
        ax.set_facecolor('#FAF9F6')
        fig.patch.set_facecolor('#FAF9F6')

        plt.title('æ³•å¾‹æ¡ˆä¾‹ç›¸ä¼¼åº¦é¢„æµ‹å¯¹æ¯”é›·è¾¾å›¾', fontsize=18,
                  fontweight='bold', color='#4B0082', pad=30)
        plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0),
                   fontsize=11, framealpha=0.9)

        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… æ¯”è¾ƒé›·è¾¾å›¾å·²ä¿å­˜: {output_path}")

        return all_probs

    def create_summary_dashboard(self, output_dir='./simple_purple_dashboard'):
        """åˆ›å»ºç»¼åˆä»ªè¡¨æ¿"""
        print("=" * 60)
        print("ğŸ¨ ç®€åŒ–ç¾è§‚åˆ†æ - ç´«è‰²é…è‰²æ–¹æ¡ˆ")
        print("=" * 60)

        os.makedirs(output_dir, exist_ok=True)

        # ç¤ºä¾‹æ–‡æœ¬
        texts = [
            "è¢«å‘Šäººç›—çªƒæ‰‹æœºä»·å€¼3000å…ƒ [SEP] ç›—çªƒç½ªç«‹æ¡ˆæ ‡å‡†ä¸º2000-50000å…ƒ",
            "äº¤é€šäº‹æ•…è‡´äººæ­»äº¡ [SEP] äº¤é€šè‚‡äº‹ç½ªéœ€è´Ÿåˆ‘äº‹è´£ä»»",
            "åˆåŒè¿çº¦æŸå¤±100ä¸‡ [SEP] è¿çº¦é‡‘ä¸å¾—è¶…è¿‡å®é™…æŸå¤±çš„30%",
            "è´ªæ±¡å…¬æ¬¾50ä¸‡å…ƒ [SEP] è´ªæ±¡æ•°é¢å·¨å¤§æ ‡å‡†ä¸º20-300ä¸‡å…ƒ",
            "æ•…æ„ä¼¤å®³è‡´äººè½»ä¼¤ [SEP] æ•…æ„ä¼¤å®³ç½ªéœ€è¾¾åˆ°è½»ä¼¤æ ‡å‡†"
        ]

        # 1. Tokené‡è¦æ€§åˆ†æ
        print("\n1. Tokené‡è¦æ€§åˆ†æ...")
        self.analyze_token_importance(
            texts[0],
            os.path.join(output_dir, 'token_importance.png')
        )

        # 2. é¢„æµ‹çƒ­åŠ›å›¾
        print("\n2. é¢„æµ‹çƒ­åŠ›å›¾åˆ†æ...")
        self.create_prediction_heatmap(
            texts,
            os.path.join(output_dir, 'prediction_heatmap.png')
        )

        # 3. æ¯”è¾ƒé›·è¾¾å›¾
        print("\n3. æ¯”è¾ƒé›·è¾¾å›¾åˆ†æ...")
        self.create_comparison_radar(
            texts,
            os.path.join(output_dir, 'comparison_radar.png')
        )

        # 4. åˆ›å»ºHTMLæŠ¥å‘Š
        self.create_simple_html_report(output_dir)

        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_dir}")

    def create_simple_html_report(self, output_dir):
        """åˆ›å»ºç®€å•çš„HTMLæŠ¥å‘Š"""
        html_content = """
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>æ³•å¾‹æ¨¡å‹åˆ†ææŠ¥å‘Š - ç®€åŒ–ç‰ˆ</title>
    <style>
        body {
            font-family: 'Microsoft YaHei', sans-serif;
            margin: 0;
            padding: 20px;
            background: #f5f0ff;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(148, 0, 211, 0.1);
        }
        .header {
            text-align: center;
            margin-bottom: 40px;
        }
        .header h1 {
            color: #4B0082;
            font-size: 2em;
            background: linear-gradient(45deg, #9370DB, #4B0082);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .chart-container {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));
            gap: 20px;
            margin-bottom: 40px;
        }
        .chart-box {
            background: #FAF9F6;
            border-radius: 8px;
            padding: 15px;
            border: 1px solid #E6E6FA;
        }
        .chart-box h3 {
            color: #6A5ACD;
            margin-top: 0;
        }
        .chart-img {
            width: 100%;
            border-radius: 5px;
        }
        .footer {
            text-align: center;
            color: #666;
            font-size: 0.9em;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“ˆ æ³•å¾‹åŒ¹é…æ¨¡å‹åˆ†ææŠ¥å‘Š</h1>
            <p>ç®€åŒ–åˆ†æç‰ˆ - ç´«è‰²æ¸å˜é…è‰²</p>
        </div>

        <div class="chart-container">
            <div class="chart-box">
                <h3>ğŸ” Tokené‡è¦æ€§åˆ†æ</h3>
                <img src="token_importance.png" class="chart-img">
                <p>æ˜¾ç¤ºå¯¹é¢„æµ‹ç»“æœæœ€é‡è¦çš„tokenåŠå…¶å½±å“ç¨‹åº¦</p>
            </div>

            <div class="chart-box">
                <h3>ğŸ”¥ é¢„æµ‹æ¦‚ç‡çƒ­åŠ›å›¾</h3>
                <img src="prediction_heatmap.png" class="chart-img">
                <p>ä¸åŒæ¡ˆä¾‹åœ¨å„ç›¸ä¼¼åº¦ç­‰çº§çš„é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ</p>
            </div>

            <div class="chart-box">
                <h3>ğŸ“¡ å¤šæ¡ˆä¾‹æ¯”è¾ƒé›·è¾¾å›¾</h3>
                <img src="comparison_radar.png" class="chart-img">
                <p>å¤šä¸ªæ¡ˆä¾‹åœ¨ä¸åŒç›¸ä¼¼åº¦ç­‰çº§çš„æ¯”è¾ƒåˆ†æ</p>
            </div>
        </div>

        <div class="footer">
            <p>ç”Ÿæˆæ—¶é—´ï¼š""" + pd.Timestamp.now().strftime('%Y-%m-%d %H:%M') + """</p>
            <p>åˆ†ææ–¹æ³•ï¼šTokené®ç›–æ³• + æ¦‚ç‡é¢„æµ‹åˆ†æ</p>
        </div>
    </div>
</body>
</html>
        """

        html_path = os.path.join(output_dir, 'simple_report.html')
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)

        print(f"ğŸ“„ HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {html_path}")


# ================== ä¸»ç¨‹åº ==================
if __name__ == "__main__":
    # è®¾ç½®æ¨¡å‹è·¯å¾„
    MODEL_PATH = "E:\\Py_Dev\\IceBerg\\lawformer_matching_model"

    # æ£€æŸ¥è·¯å¾„
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {MODEL_PATH}")
    else:
        try:
            # åˆ›å»ºåˆ†æå™¨
            analyzer = SimplePurpleAnalyzer(MODEL_PATH)

            # è¿è¡Œåˆ†æ
            analyzer.create_summary_dashboard('./simple_purple_results')

        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            import traceback

            traceback.print_exc()